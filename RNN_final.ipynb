{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0JLcW1xlmGJJ",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:23:25.730784Z",
     "start_time": "2023-12-21T13:23:25.075316Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEafQJj9qZJY"
   },
   "source": [
    "#Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gf9VGlAYvJ6U",
    "outputId": "5bb9e346-50a0-4ad3-c9fb-7c8fdbedcbef",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:23:25.735382Z",
     "start_time": "2023-12-21T13:23:25.731463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ericsaikali/Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/tokamak-unsupervised/QCEH_data\n",
      "['TCV_DATAno61056.parquet', 'TCV_DATAno61057.parquet', 'TCV_DATAno64438.parquet', 'TCV_DATAno64467.parquet', 'TCV_DATAno64469.parquet', 'TCV_DATAno64495.parquet', 'TCV_DATAno64950.parquet', 'TCV_DATAno66166.parquet', 'TCV_DATAno66169.parquet', 'TCV_DATAno70302.parquet', 'TCV_DATAno70305.parquet', 'TCV_DATAno70306.parquet', 'TCV_DATAno70310.parquet', 'TCV_DATAno70311.parquet', 'TCV_DATAno70313.parquet', 'TCV_DATAno70654.parquet', 'TCV_DATAno70656.parquet', 'TCV_DATAno70657.parquet', 'TCV_DATAno71344.parquet', 'TCV_DATAno71345.parquet', 'TCV_DATAno71351.parquet', 'TCV_DATAno73532.parquet', 'TCV_DATAno73784.parquet', 'TCV_DATAno73785.parquet', 'TCV_DATAno73786.parquet', 'TCV_DATAno73838.parquet', 'TCV_DATAno73846.parquet', 'TCV_DATAno75461.parquet', 'TCV_DATAno75464.parquet', 'TCV_DATAno78058.parquet', 'TCV_DATAno78061.parquet', 'TCV_DATAno78064.parquet', 'TCV_DATAno78069.parquet', 'TCV_DATAno78089.parquet', 'TCV_DATAno78090.parquet', 'TCV_DATAno78091.parquet', 'TCV_DATAno78104.parquet', 'TCV_DATAno78260.parquet', 'TCV_DATAno78261.parquet', 'TCV_DATAno78262.parquet', 'TCV_DATAno78368.parquet', 'TCV_DATAno78382.parquet', 'TCV_DATAno78510.parquet', 'TCV_DATAno78512.parquet', 'TCV_DATAno78518.parquet', 'TCV_DATAno78521.parquet', 'TCV_DATAno78524.parquet', 'TCV_DATAno78597.parquet', 'TCV_DATAno78598.parquet', 'TCV_DATAno78600.parquet', 'TCV_DATAno78601.parquet', 'TCV_DATAno78602.parquet', 'TCV_DATAno78603.parquet', 'TCV_DATAno78604.parquet', 'TCV_DATAno78606.parquet', 'TCV_DATAno78608.parquet', 'TCV_DATAno78611.parquet', 'TCV_DATAno78637.parquet', 'TCV_DATAno78639.parquet', 'TCV_DATAno78656.parquet']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericsaikali/Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/tokamak-unsupervised/venv/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# Turn to False to run locally\n",
    "USE_GOOGLE_COLAB = False\n",
    "\n",
    "if USE_GOOGLE_COLAB:\n",
    "  # Mount MyDrive/QCEH_data/ to fetch training and testing data\n",
    "  from google.colab import drive\n",
    "\n",
    "  drive.mount('/content/drive')\n",
    "  import sys\n",
    "  folder_name = 'drive/MyDrive/QCEH_data/'\n",
    "  sys.path.append(folder_name)\n",
    "  %cd 'drive/MyDrive/QCEH_data/'\n",
    "else:\n",
    "  %cd 'QCEH_data/'\n",
    "\n",
    "file_names = [f for f in os.listdir('./') if f.endswith('.parquet')]\n",
    "file_names.sort()\n",
    "print(file_names)\n",
    "\n",
    "parquet_filename = 'TCV_DATAno64467.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fogc8k679kTN"
   },
   "source": [
    "# Constants for trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "p-xVefiemGJM",
    "outputId": "0feb6e53-050a-4e4d-b929-2a8c4d874f73",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:23:25.746614Z",
     "start_time": "2023-12-21T13:23:25.736779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9TNHLId8-Tnj",
    "outputId": "b38653cb-277a-4329-89d8-92d5839ecb87",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:23:25.746957Z",
     "start_time": "2023-12-21T13:23:25.740031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TCV_DATAno61056.parquet', 'TCV_DATAno61057.parquet', 'TCV_DATAno64438.parquet', 'TCV_DATAno64467.parquet', 'TCV_DATAno64469.parquet', 'TCV_DATAno64495.parquet', 'TCV_DATAno64950.parquet', 'TCV_DATAno66166.parquet', 'TCV_DATAno66169.parquet', 'TCV_DATAno70302.parquet', 'TCV_DATAno70305.parquet', 'TCV_DATAno70306.parquet', 'TCV_DATAno70313.parquet', 'TCV_DATAno70654.parquet', 'TCV_DATAno70656.parquet', 'TCV_DATAno70657.parquet', 'TCV_DATAno71344.parquet', 'TCV_DATAno71345.parquet', 'TCV_DATAno71351.parquet', 'TCV_DATAno73532.parquet', 'TCV_DATAno73784.parquet', 'TCV_DATAno73785.parquet', 'TCV_DATAno73786.parquet', 'TCV_DATAno73846.parquet', 'TCV_DATAno75461.parquet', 'TCV_DATAno75464.parquet', 'TCV_DATAno78058.parquet', 'TCV_DATAno78061.parquet', 'TCV_DATAno78064.parquet', 'TCV_DATAno78069.parquet', 'TCV_DATAno78089.parquet', 'TCV_DATAno78090.parquet', 'TCV_DATAno78091.parquet', 'TCV_DATAno78104.parquet', 'TCV_DATAno78260.parquet', 'TCV_DATAno78261.parquet', 'TCV_DATAno78262.parquet', 'TCV_DATAno78368.parquet', 'TCV_DATAno78382.parquet', 'TCV_DATAno78510.parquet', 'TCV_DATAno78512.parquet', 'TCV_DATAno78518.parquet', 'TCV_DATAno78521.parquet', 'TCV_DATAno78524.parquet', 'TCV_DATAno78597.parquet', 'TCV_DATAno78598.parquet', 'TCV_DATAno78600.parquet', 'TCV_DATAno78601.parquet', 'TCV_DATAno78602.parquet', 'TCV_DATAno78656.parquet']\n",
      "['TCV_DATAno70310.parquet', 'TCV_DATAno70311.parquet', 'TCV_DATAno73838.parquet', 'TCV_DATAno78603.parquet', 'TCV_DATAno78604.parquet', 'TCV_DATAno78606.parquet', 'TCV_DATAno78608.parquet', 'TCV_DATAno78611.parquet', 'TCV_DATAno78637.parquet', 'TCV_DATAno78639.parquet']\n",
      "50 10 60\n"
     ]
    }
   ],
   "source": [
    "file_names = [f for f in os.listdir('./') if f.endswith('.parquet')]\n",
    "file_names.sort()\n",
    "\n",
    "test_shot_names = {\n",
    "    \"TCV_DATAno70310.parquet\",\n",
    "    \"TCV_DATAno70311.parquet\",\n",
    "    \"TCV_DATAno73838.parquet\",\n",
    "    \"TCV_DATAno78603.parquet\",\n",
    "    \"TCV_DATAno78604.parquet\",\n",
    "    \"TCV_DATAno78606.parquet\",\n",
    "    \"TCV_DATAno78608.parquet\",\n",
    "    \"TCV_DATAno78611.parquet\",\n",
    "    \"TCV_DATAno78637.parquet\",\n",
    "    \"TCV_DATAno78639.parquet\"\n",
    "}\n",
    "\n",
    "train_filenames = []\n",
    "test_filenames = []\n",
    "for file in file_names:\n",
    "  if file in test_shot_names:\n",
    "    test_filenames.append(file)\n",
    "  else:\n",
    "    train_filenames.append(file)\n",
    "\n",
    "print(train_filenames)\n",
    "print(test_filenames)\n",
    "print(len(train_filenames), len(test_filenames), len(train_filenames) + len(test_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3RQTo9p-T61",
    "outputId": "e5d3b2ed-b107-4d76-d4a6-9160c9dd09e8",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:23:25.749266Z",
     "start_time": "2023-12-21T13:23:25.743368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "19"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GENERAL_INPUTS = [\"shotnumber\", \"time\"]\n",
    "MACHINE_INPUTS = [\"isbaffled\", \"ip\",\"b0\",\"nel\",\"ptot\",\"pdiv\",\"q95\",\"betan\",\"kappa\",\"deltaavg\",\"deltaupp\",\n",
    "                  \"deltalow\",\"gapin\",\"gapout\",\"zmag\",\"rmag\",\"rmin\",\"lpar_ot\",\"zeff\"]\n",
    "LABEL = [\"LHD_label\"]\n",
    "INPUTS = GENERAL_INPUTS + MACHINE_INPUTS + LABEL\n",
    "\n",
    "MAX_SHOT_LENGTH = 11001\n",
    "\n",
    "input_size = len(MACHINE_INPUTS)\n",
    "output_size = 4\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "len(MACHINE_INPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3EE36Oxqxtv"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mmvuI5ZYdyJo",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:23:25.765528Z",
     "start_time": "2023-12-21T13:23:25.748198Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_dataframe(data, to_length, columns=INPUTS):\n",
    "  # Padd shot' samples with dummy values at the beginning if the shot is too short\n",
    "  if to_length != None and data.shape[0] < to_length:\n",
    "    df = pd.DataFrame(0, index=np.arange(to_length - data.shape[0]), columns=columns)\n",
    "    data = pd.concat([df, data], axis=0, ignore_index=True)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-9tuf7Kzd7h4",
    "outputId": "dd642d51-3075-4962-a68d-d1619f988a78",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:23:26.074320Z",
     "start_time": "2023-12-21T13:23:25.752247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels distribution:  tensor([0.0360, 0.2290, 0.2247, 0.5103])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/vpp5gf_96v7f5w4frq2kpfn00000gn/T/ipykernel_10709/3394722215.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return torch.tensor(x_mean, dtype=torch.float32), torch.tensor(x_std, dtype=torch.float32), torch.tensor(labels_distribution, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "def read_data(file_names, expected_length=None):\n",
    "  df_list = [\n",
    "      pad_dataframe(\n",
    "          pd.read_parquet(x).drop(columns=['alpha', 'H98y2calc'], errors='ignore'),\n",
    "          expected_length\n",
    "      )\n",
    "      for x in file_names]\n",
    "  df_list = pd.concat(df_list, ignore_index=True)\n",
    "  df_list = df_list[MACHINE_INPUTS + LABEL]\n",
    "\n",
    "  X = df_list.drop([\"LHD_label\"], axis=1)\n",
    "  y = df_list[\"LHD_label\"]\n",
    "\n",
    "  return df_list, X, y\n",
    "\n",
    "def analyse_data(file_names):\n",
    "  _, X, y = read_data(file_names, MAX_SHOT_LENGTH)\n",
    "\n",
    "  x_mean = np.mean(X, axis=0)\n",
    "  x_std = np.std(X, axis=0)\n",
    "\n",
    "  y_compared = np.arange(output_size)[:,np.newaxis] == np.array(y)\n",
    "  labels_distribution = np.sum(y_compared, axis=1) / y.shape[0]\n",
    "\n",
    "  return torch.tensor(x_mean, dtype=torch.float32), torch.tensor(x_std, dtype=torch.float32), torch.tensor(labels_distribution, dtype=torch.float32)\n",
    "\n",
    "x_mean, x_std, labels_distribution = analyse_data(train_filenames)\n",
    "print(\"labels distribution: \", labels_distribution)\n",
    "\n",
    "torch.save(x_mean, \"x_mean.pt\")\n",
    "torch.save(x_std, \"x_std.pt\")\n",
    "torch.save(labels_distribution, \"labels_distribution.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAw38cbDaf-9"
   },
   "source": [
    "# Loaders for datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SJSZz9QHanxz",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:23:26.358729Z",
     "start_time": "2023-12-21T13:23:26.072810Z"
    }
   },
   "outputs": [],
   "source": [
    "class QCEH_Dataset(Dataset):\n",
    "  def __init__(self, file_names, sequence_length, mean, std, transform=None):\n",
    "    self.samples = []\n",
    "    self.labels = []\n",
    "\n",
    "    for file_name in file_names:\n",
    "      _, X, y = read_data([file_name], sequence_length)\n",
    "      X = torch.tensor(X.values, dtype=torch.float32)\n",
    "      y = torch.tensor(y.values, dtype=torch.float32)\n",
    "      X_normalized = (X - torch.unsqueeze(mean, 0)) / torch.unsqueeze(std, 0)\n",
    "\n",
    "      if transform:\n",
    "        X_normalized = transform(X_normalized)\n",
    "\n",
    "      self.samples.append(X_normalized.to(device))\n",
    "      self.labels.append(y.to(device))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.samples)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.samples[idx], self.labels[idx]\n",
    "\n",
    "train_data = QCEH_Dataset(\n",
    "    train_filenames,\n",
    "    MAX_SHOT_LENGTH,\n",
    "    x_mean,\n",
    "    x_std\n",
    ")\n",
    "\n",
    "test_data = QCEH_Dataset(\n",
    "    test_filenames,\n",
    "    MAX_SHOT_LENGTH,\n",
    "    x_mean,\n",
    "    x_std\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UwRnVZX-BKzw",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:23:26.654960Z",
     "start_time": "2023-12-21T13:23:26.362828Z"
    }
   },
   "outputs": [],
   "source": [
    "class QCEH_Dataset_Downsampled(Dataset):\n",
    "  def __init__(self, file_names, mean, std, step_size, sub_sequence_length, sequence_length, transform=None, record=False):\n",
    "    self.step_size = step_size\n",
    "    self.sequence_length = sequence_length\n",
    "    self.sub_sequence_length = sub_sequence_length\n",
    "\n",
    "    self.samples = []\n",
    "    self.labels = []\n",
    "\n",
    "    for file_name in file_names:\n",
    "      _, X, y = read_data([file_name], sequence_length)\n",
    "      X = torch.tensor(X.values, dtype=torch.float32)\n",
    "      y = torch.tensor(y.values, dtype=torch.float32)\n",
    "      X_normalized = (X - torch.unsqueeze(mean, 0)) / torch.unsqueeze(std, 0)\n",
    "\n",
    "      if transform:\n",
    "        X_normalized = transform(X_normalized)\n",
    "\n",
    "      self.samples.append(X_normalized)\n",
    "      self.labels.append(y)\n",
    "\n",
    "    if record:\n",
    "      self.record = torch.zeros((output_size), dtype=torch.float32)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.samples)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    X = self.samples[idx]\n",
    "\n",
    "    sub_sequence_id = random.randint(0, self.step_size - 1)\n",
    "    sub_sequence_ids = torch.arange(0, self.sequence_length)\n",
    "    sub_sequence_ids = sub_sequence_ids[\n",
    "        sub_sequence_ids % self.step_size == sub_sequence_id\n",
    "        ]\n",
    "    sub_sequence_ids = sub_sequence_ids[:self.sub_sequence_length]\n",
    "\n",
    "    samples = self.samples[idx][sub_sequence_ids,:]\n",
    "    labels = self.labels[idx][sub_sequence_ids]\n",
    "\n",
    "    if self.record != None:\n",
    "      for i in range(output_size):\n",
    "        self.record[i] += torch.sum(labels == i)\n",
    "\n",
    "    samples = samples.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    return samples, labels\n",
    "\n",
    "  def get_record(self):\n",
    "    return self.record.clone().detach()\n",
    "\n",
    "downsample_step = 11\n",
    "downsample_sequence_size = math.floor(MAX_SHOT_LENGTH / downsample_step)\n",
    "\n",
    "downsampled_training_data = QCEH_Dataset_Downsampled(\n",
    "    train_filenames,\n",
    "    x_mean,\n",
    "    x_std,\n",
    "    downsample_step,\n",
    "    downsample_sequence_size,\n",
    "    MAX_SHOT_LENGTH,\n",
    "    record=True\n",
    ")\n",
    "\n",
    "downsampled_test_data = QCEH_Dataset_Downsampled(\n",
    "    test_filenames,\n",
    "    x_mean,\n",
    "    x_std,\n",
    "    downsample_step,\n",
    "    downsample_sequence_size,\n",
    "    MAX_SHOT_LENGTH,\n",
    "    record=True\n",
    ")\n",
    "\n",
    "downsampled_train_dataloader = DataLoader(downsampled_training_data, batch_size=batch_size, shuffle=True)\n",
    "downsampled_test_dataloader = DataLoader(downsampled_test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tvq-lviJq59f"
   },
   "source": [
    "#General definitions for RNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NFIrXJ8YXxM-",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:23:26.659284Z",
     "start_time": "2023-12-21T13:23:26.657906Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function constructing a multiclass confusion matrix\n",
    "\n",
    ":param y_predicted: pd.Series containing the predicted labels\n",
    ":param y_expected: pd.Series containing the expected labels\n",
    ":return: pd.Dataframe containing the multiclass confusion matrix\n",
    "with columns as true labels and rows are predicted labels\n",
    "\"\"\"\n",
    "def confusion_matrix(y_predicted, y_expected, display_matrix=False):\n",
    "  predicted_labels = y_predicted.unique()\n",
    "  expected_labels = np.sort(y_expected.unique())\n",
    "\n",
    "  mtrx = pd.DataFrame(0, columns=expected_labels, index=expected_labels)\n",
    "\n",
    "  for expected_label in expected_labels:\n",
    "    for predicted_label in predicted_labels:\n",
    "      count = sum((y_expected == expected_label) & (y_predicted == predicted_label))\n",
    "      mtrx.at[predicted_label, expected_label] = count\n",
    "\n",
    "  if (display_matrix):\n",
    "    display(mtrx)\n",
    "\n",
    "  return mtrx\n",
    "\n",
    "\"\"\"\n",
    "Function retrieving the true values of a confusion matrix\n",
    "\n",
    ":param matrix: confusion matrix\n",
    ":return: list of all the diagonal values\n",
    "\"\"\"\n",
    "def diag(matrix):\n",
    "  if len(matrix.index) <= len(matrix.columns):\n",
    "    zipped = zip(matrix.index, matrix.columns[:len(matrix.index)])\n",
    "  else:\n",
    "    zipped = zip(matrix.index[:len(matrix.columns)], matrix.columns)\n",
    "\n",
    "  diag = []\n",
    "  for idx,col in zipped:\n",
    "    diag.append(matrix.at[idx,col])\n",
    "  return diag\n",
    "\n",
    "\"\"\"\n",
    "Function computing the precision associated with a confusion matrix\n",
    ":param matrix: confusion matrix\n",
    ":return: precision score\n",
    "\"\"\"\n",
    "def multi_precision(matrix, display_result=False):\n",
    "  tp = diag(matrix)\n",
    "  pred_p = matrix.sum(axis=1)\n",
    "  if display_result:\n",
    "    display(pred_p)\n",
    "  return (tp / pred_p).fillna(0)\n",
    "\n",
    "\"\"\"\n",
    "Function computing the recall associated with a confusion matrix\n",
    ":param matrix: confusion matrix\n",
    ":return: recall score\n",
    "\"\"\"\n",
    "def multi_recall(matrix, display_result=False):\n",
    "  tp = diag(matrix)\n",
    "  acutal_p = matrix.sum(axis=0)\n",
    "  if display_result:\n",
    "    display(acutal_p)\n",
    "  return (tp / acutal_p).fillna(0)\n",
    "\n",
    "\"\"\"\n",
    "Function computing the F1-score associated with a confusion matrix\n",
    ":param matrix: confusion matrix\n",
    ":return: F1-score\n",
    "\"\"\"\n",
    "def multi_f1_score(matrix, display_result=False):\n",
    "  recall = multi_recall(matrix, display_result)\n",
    "  precision = multi_precision(matrix, display_result)\n",
    "\n",
    "  multiplied = recall.multiply(precision)\n",
    "  summed = recall + precision\n",
    "  return (2 * multiplied / summed).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Nw12zYzOhkCO",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:23:26.668593Z",
     "start_time": "2023-12-21T13:23:26.665674Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_output_to_states(output):\n",
    "  # Convert predictions to probability of each class\n",
    "  prob = F.softmax(output, dim=1).data\n",
    "  # Taks the class with the highest probability score from the output\n",
    "  output_states = torch.max(prob, dim=1)\n",
    "  return output_states[1]\n",
    "\n",
    "def run_model(model, output_size, dataloader, loss_fn, optimizer=None, display_matrix=False):\n",
    "  loss_total = 0\n",
    "\n",
    "  y_predicted = torch.empty((0,), dtype=torch.float32).to(device)\n",
    "  y_labels = torch.empty((0,), dtype=torch.float32).to(device)\n",
    "\n",
    "  for x, y in dataloader:\n",
    "    if optimizer:\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    output, hidden = model(x)\n",
    "    output_states = decode_output_to_states(output)\n",
    "\n",
    "    loss = loss_fn(output, y.long().view(-1))\n",
    "\n",
    "    if optimizer:\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    loss_total += loss\n",
    "\n",
    "    # Records outputs for confusion matrix computation\n",
    "    y_predicted = torch.cat([y_predicted, torch.reshape(output_states, (-1,))])\n",
    "    y_labels = torch.cat([y_labels, torch.reshape(y, (-1,))])\n",
    "\n",
    "  # Confusion matrix & f1 score\n",
    "  matrix = confusion_matrix(pd.Series(y_predicted.cpu()), pd.Series(y_labels.cpu()), display_matrix=display_matrix)\n",
    "  multi_f1 = multi_f1_score(matrix)\n",
    "\n",
    "  return loss_total.item(), matrix, multi_f1\n",
    "\n",
    "\n",
    "def train_model(model, output_size, dataloader, optimizer, loss_fn, n_epochs):\n",
    "  model.train()\n",
    "\n",
    "  loss_history = []\n",
    "  f1_scores = []\n",
    "  for out in range(output_size):\n",
    "    f1_scores.append([])\n",
    "\n",
    "  # Training Run\n",
    "  for epoch in range(0, n_epochs):\n",
    "    loss, _, multi_f1 = run_model(model, output_size, train_dataloader, loss_fn,\n",
    "                                  optimizer=optimizer, display_matrix=(epoch == n_epochs - 1))\n",
    "\n",
    "    loss_history.append(loss)\n",
    "    for out in range(output_size):\n",
    "      f1_scores[out].append(multi_f1[out].item())\n",
    "\n",
    "    if epoch == 0:\n",
    "      print('Training... [', end='')\n",
    "    if epoch%10 == 0:\n",
    "      print('#', end='')\n",
    "    if epoch == n_epochs - 1:\n",
    "      print('] done!')\n",
    "      print('Epoch: {}/{}.............'.format(epoch + 1, n_epochs), end=' ')\n",
    "      print(\"Loss: {:.4f}\".format(loss))\n",
    "      for out in range(output_size):\n",
    "        print(\"\\t state {}: F1 score = {:.4f}\".format(out, f1_scores[out][-1]))\n",
    "\n",
    "  # Plot results\n",
    "  fig, ax = plt.subplots(1, 1)\n",
    "  ax.plot(loss_history, 'm', label=\"Loss\")\n",
    "  ax.set_xlabel(\"Epoch\")\n",
    "  ax.set_ylabel(\"Loss\")\n",
    "  ax2 = ax.twinx()\n",
    "  ax2.set_ylabel('F1 score')\n",
    "  for out in range(output_size):\n",
    "    ax2.plot(f1_scores[out], label='F1 score state {}'.format(out))\n",
    "  ax.legend(loc=\"upper left\")\n",
    "  ax2.legend(loc=\"upper right\")\n",
    "  plt.show()\n",
    "\n",
    "def test_model(model, output_size, lossFn, test_dataloader):\n",
    "  model.eval()\n",
    "\n",
    "  loss, _, multi_f1 = run_model(model, output_size, test_dataloader, lossFn, display_matrix=True)\n",
    "\n",
    "  print(\"Evaluating model on testing data:\")\n",
    "  print(\"Loss: {:.4f}\".format(loss))\n",
    "  for out in range(output_size):\n",
    "    print(\"\\t state {}: F1 score = {:.4f}\".format(out, multi_f1[out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "umTPNpgvxz_s",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:23:26.671127Z",
     "start_time": "2023-12-21T13:23:26.668Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss(weight=labels_distribution.to(device))\n",
    "\n",
    "#hyperparameters\n",
    "n_epochs_rnn = 400\n",
    "n_epochs_lstm = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1Ou9NOPdBPp"
   },
   "source": [
    "# RNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EzbloLGtnqHa",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:23:26.675513Z",
     "start_time": "2023-12-21T13:23:26.671735Z"
    }
   },
   "outputs": [],
   "source": [
    "# create our RNN based network with an RNN followed by a linear layer\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, n_layers, drop_prob):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Defining the layers\n",
    "        # RNN Layer\n",
    "        self.RNN = nn.RNN(input_size=input_size,\n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=n_layers,\n",
    "                          nonlinearity='tanh',\n",
    "                          batch_first=True,\n",
    "                          dropout=drop_prob)\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "      batch_size = x.size(0)\n",
    "\n",
    "      # Initializing hidden state for first input using method defined below\n",
    "      hidden = self.init_hidden(batch_size)\n",
    "\n",
    "      # Passing in the input and hidden state into the model and obtaining outputs\n",
    "      out, hidden = self.RNN(x, hidden)\n",
    "\n",
    "      # Passing trough the dropout layer\n",
    "      out = self.dropout(out)\n",
    "\n",
    "      # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "      out = out.contiguous().view(-1, self.hidden_dim)\n",
    "      out = self.fc(out)\n",
    "\n",
    "      return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim, dtype=torch.float32)\n",
    "        hidden = hidden.to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_07CSWkqe-6Y",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:23:26.686372Z",
     "start_time": "2023-12-21T13:23:26.674729Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_RNN_model(input_size, output_size, num_layers, hidden_size, drop_prob, learning_rate, n_epochs, train_dataloader, loss_fn):\n",
    "  print(\"---------------------------------------\")\n",
    "  print(\"Training RNN model with hyperparameters:\")\n",
    "  print(\"hidden_size = \", hidden_size)\n",
    "  print(\"num_layers = \", num_layers)\n",
    "  print(\"drop_prob = \", drop_prob)\n",
    "  print(\"learning_rate = \", learning_rate)\n",
    "  print(\"n_epochs = \", n_epochs)\n",
    "\n",
    "  # Create our network instance, pick loss function and optimizer\n",
    "  model = RNN(input_size, output_size, hidden_size, num_layers, drop_prob)\n",
    "  model = model.to(device)\n",
    "\n",
    "  # Define Loss, Optimizer\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  # Train model\n",
    "  train_model(model, output_size, train_dataloader, optimizer, loss_fn, n_epochs)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmdIM644tte0"
   },
   "outputs": [],
   "source": [
    "for learning_rate_exp in range(-5, -1):\n",
    "  learning_rate = 10 ** learning_rate_exp\n",
    "\n",
    "  for num_layers_exp in range(0, 4):\n",
    "    num_layers = 2 ** num_layers_exp\n",
    "\n",
    "    for hidden_size_exp in range(4, 7):\n",
    "      hidden_size = 2 ** hidden_size_exp\n",
    "\n",
    "      for drop_prob in [0.2, 0.5, 0.7]:\n",
    "        rnn_trained_model = train_RNN_model(input_size, output_size, num_layers, hidden_size,\n",
    "                                      drop_prob, learning_rate, n_epochs_rnn, train_dataloader, cross_entropy)\n",
    "        if num_layers == 1:\n",
    "          break\n",
    "\n",
    "        test_model(rnn_trained_model, output_size, cross_entropy, test_dataloader)\n",
    "\n",
    "        model_name = \"./rnn_10^{}_{}_{}_{:.1f}\".format(learning_rate_exp, num_layers, hidden_size_exp, drop_prob)\n",
    "        torch.save(rnn_trained_model.state_dict(), model_name)\n",
    "\n",
    "        print(model_name, \" is trained !\")\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PA_6XQcqK3T"
   },
   "source": [
    "# LSTM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_ISUJrZgqNzI",
    "ExecuteTime": {
     "end_time": "2023-12-21T13:24:01.480891Z",
     "start_time": "2023-12-21T13:24:01.468023Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "\n",
    "        # Passing trough the dropout layer\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden\n",
    "\n",
    "def train_LSTM_model(input_size, output_size, hidden_size, num_layers, learning_rate, drop_prob, n_epochs, train_dataloader, loss_fn):\n",
    "  print(\"---------------------------------------\")\n",
    "  print(\"Training LSTM model with hyperparameters:\")\n",
    "  print(\"hidden_size = \", hidden_size)\n",
    "  print(\"num_layers = \", num_layers)\n",
    "  print(\"learning_rate = \", learning_rate)\n",
    "  print(\"drop_prob = \", drop_prob)\n",
    "  print(\"n_epochs = \", n_epochs)\n",
    "\n",
    "  # Create our network instance, pick loss function and optimizer\n",
    "  model = LSTM(input_size, output_size, hidden_size, num_layers)\n",
    "  model = model.to(device)\n",
    "\n",
    "  # Define Loss, Optimizer\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  # Train model\n",
    "  train_model(model, output_size, train_dataloader, optimizer, loss_fn, n_epochs)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6hkrxaFNk1uW",
    "outputId": "4028c6cd-aef9-464e-fb0a-ac22bf292538"
   },
   "outputs": [],
   "source": [
    "for learning_rate_exp in range(-5, -1):\n",
    "  learning_rate = 10 ** learning_rate_exp\n",
    "\n",
    "  for num_layers_exp in range(1, 3):\n",
    "    num_layers = 2 ** num_layers_exp\n",
    "\n",
    "    for hidden_size_exp in range(5, 8):\n",
    "      hidden_size = 2 ** hidden_size_exp\n",
    "\n",
    "      for drop_prob in [0.2, 0.5, 0.7]:\n",
    "        ltsm_trained_model = train_LSTM_model(input_size, output_size, hidden_size,\n",
    "                                      num_layers, learning_rate, drop_prob,\n",
    "                                      n_epochs_lstm, downsampled_train_dataloader, cross_entropy)\n",
    "\n",
    "        test_model(ltsm_trained_model, output_size, cross_entropy, downsampled_test_dataloader)\n",
    "\n",
    "        model_name = \"./ltsm_10^{}_{}_{}_{:.1f}\".format(learning_rate_exp, num_layers, hidden_size_exp, drop_prob)\n",
    "        torch.save(ltsm_trained_model.state_dict(), model_name)\n",
    "\n",
    "        print(model_name, \" is trained !\")\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yp3gMPLZ6hz_",
    "ExecuteTime": {
     "start_time": "2023-12-21T13:23:55.023215Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
