{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T13:49:45.063951Z",
     "start_time": "2023-12-20T13:49:40.989816Z"
    },
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import scipy.stats as sts\n",
    "from scipy.interpolate import griddata\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42057ba898f7eb5e",
   "metadata": {
    "id": "42057ba898f7eb5e"
   },
   "source": [
    "### CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b467bc2c7d40cdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T13:49:45.066690Z",
     "start_time": "2023-12-20T13:49:45.063132Z"
    },
    "id": "7b467bc2c7d40cdb"
   },
   "outputs": [],
   "source": [
    "GENERAL_INPUTS = [\"shotnumber\", \"time\"]\n",
    "MACHINE_INPUTS = [\"isbaffled\", \"ip\", \"b0\", \"nel\", \"ptot\", \"pdiv\", \"q95\", \"betan\", \"kappa\", \"deltaavg\", \"deltaupp\",\n",
    "                  \"deltalow\", \"gapin\", \"gapout\", \"zmag\", \"rmag\", \"rmin\", \"lpar_ot\", \"zeff\"]\n",
    "LABEL = [\"LHD_label\"]\n",
    "INPUTS = GENERAL_INPUTS + MACHINE_INPUTS + LABEL\n",
    "precomputed_dir = 'precomputed_data/'\n",
    "\n",
    "MAX_SHOT_LENGTH = 11001\n",
    "input_size = len(MACHINE_INPUTS)\n",
    "output_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c749ca6aa195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T13:49:45.067547Z",
     "start_time": "2023-12-20T13:49:45.065155Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe4c749ca6aa195",
    "outputId": "020a3342-635b-4b73-a504-3efc9c213178"
   },
   "outputs": [],
   "source": [
    "# Turn to False to run locally\n",
    "USE_GOOGLE_COLAB = False\n",
    "\n",
    "if USE_GOOGLE_COLAB:\n",
    "  # Mount MyDrive/QCEH_data/ to fetch training and testing data\n",
    "  from google.colab import drive\n",
    "    \n",
    "  drive.mount('/content/drive')\n",
    "  import sys\n",
    "  folder_name = 'drive/MyDrive/QCEH_data/'\n",
    "  sys.path.append(folder_name)\n",
    "  %cd 'drive/MyDrive/QCEH_data/'\n",
    "else:\n",
    "  %cd 'QCEH_data/'\n",
    "\n",
    "file_names = [f for f in os.listdir('./') if f.endswith('.parquet')]\n",
    "file_names.sort()\n",
    "print(file_names)\n",
    "\n",
    "parquet_filename = 'TCV_DATAno64467.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "iRKX5kilUL9t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "iRKX5kilUL9t",
    "outputId": "8ffa78d5-5252-4d9b-d5ee-f79410fa71af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "E0FfDg9kLTrR",
   "metadata": {
    "id": "E0FfDg9kLTrR"
   },
   "outputs": [],
   "source": [
    "def pad_data(data, to_length, columns=INPUTS):\n",
    "  # Padd shot' samples with dummy values at the beginning if the shot is too short\n",
    "  if data.shape[0] < to_length:\n",
    "    df = pd.DataFrame(0, index=np.arange(to_length - data.shape[0]), columns=columns)\n",
    "    data = pd.concat([df, data], axis=0, ignore_index=True)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc1420859d19c937",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T13:49:45.081612Z",
     "start_time": "2023-12-20T13:49:45.075341Z"
    },
    "id": "cc1420859d19c937"
   },
   "outputs": [],
   "source": [
    "class LTSMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "\n",
    "        # Passing trough the dropout layer\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ntYTGTcEVLEy",
   "metadata": {
    "id": "ntYTGTcEVLEy"
   },
   "outputs": [],
   "source": [
    "def perform_pca(X, n_components = 2):\n",
    "    return PCA().fit_transform(X)\n",
    "\n",
    "def draw_reduced_space(components, s_y, n_components=2, legend_labels = None, legend_title = \"LHD Label\", title=''):\n",
    "    \"\"\"\n",
    "    Draws reduced data (components) on a 2D graph or 3D depending on the number of components (n_components)\n",
    "    and displays the labels (s_y)\n",
    "\n",
    "    legend_labels must be the labels of all the unique values in s_y (increasing order)\n",
    "    \"\"\"\n",
    "    if legend_labels is None:\n",
    "        legend_mapping = {0: 'Undefined padding mode', 1: 'L-mode', 2: 'QCE H-mode', 3: 'ELMy H-mode'}\n",
    "        unique_labels = sorted(np.unique(s_y))\n",
    "        legend_labels = [legend_mapping[label] for label in unique_labels if label in legend_mapping]\n",
    "\n",
    "        # If there's a label in s_y not in legend_mapping, handle it appropriately\n",
    "        for label in unique_labels:\n",
    "            if label not in legend_mapping:\n",
    "                print(f\"Warning: Label {label} is not defined in legend_mapping.\")\n",
    "                legend_labels.append(f\"Unknown Label {label}\")\n",
    "\n",
    "\n",
    "\n",
    "    if n_components == 1:\n",
    "        print(\"That's not a very interesting plot, go for more than a single component\")\n",
    "        return\n",
    "        #plt.scatter(components[:,0], range(len(components)), c=s_y)\n",
    "    elif n_components == 2:\n",
    "        fig = plt.figure(figsize=(10,5))\n",
    "        sc = plt.scatter(components[:,0], components[:,1], c=s_y, s=10, alpha=0.5)\n",
    "        plt.xlabel('Component 1')\n",
    "        plt.ylabel('Component 2')\n",
    "    elif n_components == 3:\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        #ax = fig.add_subplot(111, projection='3d')\n",
    "        sc = ax.scatter(components[:,0], components[:,1], components[:,2], c=s_y, s=10, alpha=0.5)\n",
    "        ax.set_xlabel('Component 1')\n",
    "        ax.set_ylabel('Component 2')\n",
    "        ax.set_zlabel('Component 3')\n",
    "        ax.set_box_aspect(aspect=None, zoom=0.85) # otherwise component 3 is cutoff\n",
    "    else:\n",
    "        print(\"That number of components can't be displayed on a graph\")\n",
    "\n",
    "    plt.legend(handles=sc.legend_elements()[0], labels=legend_labels, loc='upper right', title = legend_title)\n",
    "    plt.title(title, fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "712237ed858fabc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T13:49:45.072576Z",
     "start_time": "2023-12-20T13:49:45.069156Z"
    },
    "id": "712237ed858fabc2"
   },
   "outputs": [],
   "source": [
    "def preprocess(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    X = df[MACHINE_INPUTS]\n",
    "\n",
    "    X = torch.tensor(\n",
    "        pad_data(X, MAX_SHOT_LENGTH, MACHINE_INPUTS).values,\n",
    "        dtype=torch.float32)\n",
    "\n",
    "    x_mean = torch.load(\"x_mean.pt\")\n",
    "    x_std = torch.load(\"x_std.pt\")\n",
    "\n",
    "    X_standardized = (X - torch.unsqueeze(x_mean, 0)) / torch.unsqueeze(x_std, 0)\n",
    "    X_standardized = torch.unsqueeze(X_standardized, 0)\n",
    "    X_standardized = X_standardized.to(device)\n",
    "\n",
    "    return df, X_standardized, MACHINE_INPUTS\n",
    "\n",
    "\n",
    "def predict(X):\n",
    "    model = LTSMClassifier(input_size, output_size, 64, 2, 0.2)\n",
    "    model.load_state_dict(torch.load(\"ltsm_2_6_0p2_0p001\"))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    outputs = model(X)[0]\n",
    "    y_predicted = torch.argmax(outputs, dim=1)\n",
    "    y_predicted = pd.Series(y_predicted.cpu())\n",
    "    return y_predicted\n",
    "\n",
    "\n",
    "def show(X, y):\n",
    "    X_pca = perform_pca(X)\n",
    "    draw_reduced_space(X_pca[:, :2], y, n_components=2, legend_labels=None, legend_title=\"LHD Predicted Label\", title='2D display of the given shot PCA with predicted labels.')\n",
    "    draw_reduced_space(X_pca[:, :3], y, n_components=3, legend_labels=None, legend_title=\"LHD Predicted Label\", title='3D display of the given shot PCA with predicted labels.')\n",
    "\n",
    "def save(df, y):\n",
    "    y = pd.Series(y)\n",
    "    y.name = \"LHD Predicted Label\"\n",
    "    dataframe = pd.concat([df, y], axis=1)\n",
    "    dataframe.to_csv('prediction.csv', index=False)\n",
    "    print('file is saved !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caebce61dd5958c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T13:49:45.074867Z",
     "start_time": "2023-12-20T13:49:45.071305Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5caebce61dd5958c",
    "outputId": "08ed70b5-ec30-48d4-a40a-d7bb36969934"
   },
   "outputs": [],
   "source": [
    "def run(filename):\n",
    "    df, X, column_names = preprocess(filename)\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    y = predict(X_tensor)\n",
    "\n",
    "    nb_padding_features = X.shape[0] - df.shape[0]\n",
    "    y = y[nb_padding_features:]\n",
    "    X = X.cpu()[0,nb_padding_features:,:]\n",
    "\n",
    "    show(X.cpu(), y)\n",
    "    save(df, y)\n",
    "\n",
    "run(parquet_filename)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
